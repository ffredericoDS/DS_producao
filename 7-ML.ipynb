{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0730fc-0138-4908-96a6-08663dd991bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3483/165040978.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Merge dos dataframes\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_sales_raw, df_store_raw, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Renomeando colunas para snake_case\u001b[39;00m\n\u001b[1;32m     18\u001b[0m cols_old \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayOfWeek\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPromo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStateHoliday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSchoolHoliday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStoreType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssortment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitionDistance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitionOpenSinceMonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitionOpenSinceYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPromo2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPromo2SinceWeek\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPromo2SinceYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPromoInterval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pandas/core/generic.py:6805\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6656\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6658\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6660\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6803\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6804\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6805\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6808\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6809\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pandas/core/internals/managers.py:605\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    602\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 605\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pandas/core/internals/managers.py:1787\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m-> 1787\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pandas/core/internals/managers.py:2268\u001b[0m, in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2266\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m-> 2268\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2271\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pandas/core/internals/managers.py:2293\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2286\u001b[0m new_values: ArrayLike\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[1;32m   2290\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[1;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[0;32m-> 2293\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2295\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import inflection\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Carregando os dados\n",
    "df_sales_raw = pd.read_csv('train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('store.csv', low_memory=False)\n",
    "\n",
    "# Merge dos dataframes\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')\n",
    "df1 = df_raw.copy()\n",
    "\n",
    "# Renomeando colunas para snake_case\n",
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "            'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "            'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "            'Promo2SinceYear', 'PromoInterval']\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "df1.columns = cols_new\n",
    "\n",
    "# Conversão de tipos e tratamento de valores nulos\n",
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1['competition_distance'] = df1['competition_distance'].fillna(200000.0)\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].fillna(df1['date'].dt.month)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].fillna(df1['date'].dt.year)\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].fillna(df1['date'].dt.isocalendar().week)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].fillna(df1['date'].dt.year)\n",
    "\n",
    "# Mapeamento de meses\n",
    "month_map = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "# Tratamento de promoção\n",
    "df1['promo_interval'] = df1['promo_interval'].fillna(0)\n",
    "df1['is_promo'] = df1.apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)\n",
    "\n",
    "# Conversão de tipos\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)\n",
    "\n",
    "# Criação de novas features relacionadas a datas\n",
    "df2 = df1.copy()\n",
    "df2['year'] = df2['date'].dt.year\n",
    "df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "df2['day'] = df2['date'].dt.day\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "df2['competition_since'] = pd.to_datetime(df2['competition_open_since_year'].astype(str) + '-' + df2['competition_open_since_month'].astype(str) + '-01')\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since']) / 30).dt.days.astype(int)\n",
    "df2['promo_since'] = pd.to_datetime(df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str) + '-1', format='%Y-%W-%w') - pd.DateOffset(weeks=1)\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since']) / 7).dt.days.astype(int)\n",
    "\n",
    "# Tratamento de variáveis categóricas\n",
    "df2['assortment'] = df2['assortment'].map({'a': 'basic', 'b': 'extra', 'c': 'extended'})\n",
    "df2['state_holiday'] = df2['state_holiday'].map({'a': 'public_holiday', 'b': 'easter_holiday', 'c': 'christmas'})\n",
    "df2['month'] = df2['date'].dt.month  # Adicionando a coluna 'month'\n",
    "df3 = df2.copy()  # Copiando o DataFrame df2 para df3\n",
    "\n",
    "# Remoção de colunas e tratamento de valores nulos e zeros\n",
    "df3 = df2[(df2['open'] != 0) & (df2['sales'] > 0)]\n",
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop(columns=cols_drop)\n",
    "\n",
    "# Escalonamento de features numéricas\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "rs = RobustScaler()\n",
    "df3['competition_distance'] = rs.fit_transform(df3[['competition_distance']])\n",
    "df3['competition_time_month'] = rs.fit_transform(df3[['competition_time_month']])\n",
    "mms = MinMaxScaler()\n",
    "df3['promo_time_week'] = mms.fit_transform(df3[['promo_time_week']])\n",
    "mms1 = MinMaxScaler()\n",
    "df3['year'] = mms1.fit_transform(df3[['year']])\n",
    "\n",
    "# Codificação de variáveis categóricas\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificação de variáveis categóricas\n",
    "df3 = pd.get_dummies(df3, columns=['state_holiday'], dtype=int)\n",
    "df3['store_type'] = LabelEncoder().fit_transform(df3['store_type'])\n",
    "assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
    "df3['assortment'] = df3['assortment'].map(assortment_dict)\n",
    "\n",
    "# Transformação logarítmica na variável alvo\n",
    "df3['sales'] = np.log1p(df3['sales'])\n",
    "\n",
    "# Criação de variáveis trigonométricas\n",
    "df3['month_sin'] = np.sin(2 * np.pi * df3['month'] / 12)\n",
    "df3['month_cos'] = np.cos(2 * np.pi * df3['month'] / 12)\n",
    "df3['day_sin'] = np.sin(2 * np.pi * df3['day'] / 30)\n",
    "df3['day_cos'] = np.cos(2 * np.pi * df3['day'] / 30)\n",
    "df3['week_of_year_sin'] = np.sin(2 * np.pi * df3['week_of_year'] / 52)\n",
    "df3['week_of_year_cos'] = np.cos(2 * np.pi * df3['week_of_year'] / 52)\n",
    "df3['day_of_week_sin'] = np.sin(2 * np.pi * df3['day_of_week'] / 7)\n",
    "df3['day_of_week_cos'] = np.cos(2 * np.pi * df3['day_of_week'] / 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413e3484-1bde-4d5f-b579-c755ffc91ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62394ddc-a256-40f0-872d-18f2a908f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year','day','month','day_of_week','promo_since','competition_since','year_week']\n",
    "df6 = df6.drop(cols_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf495b9-bc86-4e2a-9155-bce1c09d5210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date\n",
       "store           \n",
       "1     2013-01-02\n",
       "2     2013-01-02\n",
       "3     2013-01-02\n",
       "4     2013-01-02\n",
       "5     2013-01-02\n",
       "...          ...\n",
       "1111  2013-01-02\n",
       "1112  2013-01-02\n",
       "1113  2013-01-02\n",
       "1114  2013-01-02\n",
       "1115  2013-01-02\n",
       "\n",
       "[1115 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = df6.loc[:,['store','date']].groupby('store').min()\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34e94e8-01c1-4958-888a-310db421256c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date\n",
       "store           \n",
       "1     2015-07-31\n",
       "2     2015-07-31\n",
       "3     2015-07-31\n",
       "4     2015-07-31\n",
       "5     2015-07-31\n",
       "...          ...\n",
       "1111  2015-07-31\n",
       "1112  2015-07-31\n",
       "1113  2015-07-31\n",
       "1114  2015-07-31\n",
       "1115  2015-07-31\n",
       "\n",
       "[1115 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = df6.loc[:,['store','date']].groupby('store').max()\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92544020-13bd-4b13-859f-daa6f9ca83f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-07-31 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = df6.loc[:,['store','date']].groupby('store').max().reset_index()['date'][0]\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c961c4dc-20e0-438d-9c0a-c6f16cddd77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-06-19 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = df6.loc[:,['store','date']].groupby('store').max().reset_index()['date'][0]-datetime.timedelta(days=6*7)\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f2d492-2d0e-4fcb-b4ae-38c88e0a36e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training min date 2013-01-01 00:00:00\n",
      "training max date 2015-06-18 00:00:00\n",
      "\n",
      "test min date 2015-06-19 00:00:00\n",
      "test max date 2015-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Selecionar linhas anteriores a '2015-06-19' para treinamento\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# Selecionar linhas a partir de '2015-06-19' para teste\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print('training min date {}'.format(X_train['date'].min()))\n",
    "print('training max date {}'.format(X_train['date'].max()))\n",
    "\n",
    "print('\\ntest min date {}'.format(X_test['date'].min()))\n",
    "print('test max date {}'.format(X_test['date'].max()))\n",
    "\n",
    "# ultimas 6 semanas para test\n",
    "#treinar com o passado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e41edda6-6489-4dbd-9f4b-682095246c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boruta in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from boruta) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from boruta) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from boruta) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from scikit-learn>=0.17.1->boruta) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from scikit-learn>=0.17.1->boruta) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d0d688-8851-49be-8f2d-67d8aa5fd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e24349c-9fde-476c-a706-2cddd8a3bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = X_train.drop(['date', 'sales'], axis=1).values\n",
    "#ravel trasnformar em vetor e nao em dataframe\n",
    "y_train_n = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e51b1c-cec1-4b3f-b199-45599ac86398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Substitua esta parte pelos seus próprios dados de treino e teste\n",
    "X_train_n = X_train.drop(['date', 'sales'], axis=1).values\n",
    "y_train_n = y_train.values.ravel()\n",
    "\n",
    "# Criar um classificador RandomForest simples com menos estimadores\n",
    "rf = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42)\n",
    "\n",
    "#passando o random forest para escolher as features mais importntes , passando auto para ele escolher como vai fazer\n",
    "#verbose para plotar , n precisa  \n",
    "#randomforest para fazer o processo varias vezes\n",
    "#fit , n pode ser data frame tem que ser numpy\n",
    "# Passar o RandomForestClassifier para o BorutaPy\n",
    "boruta = BorutaPy(rf, n_estimators=10, random_state=20)\n",
    "\n",
    "# Treinar o BorutaPy\n",
    "boruta.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc935da4-78dd-41a6-851a-7928159c16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vai fazer o rank de elevaçã ds features\n",
    "cols_selected = boruta.support_.tolist()\n",
    "#ver qual a melhor feature\n",
    "X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
    "#.colums pega só coluna\n",
    "#fazer nova coluna pq x_train virou um vetor por conta do boruta\n",
    "cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()#ver oq ele nao selecionou(ver a diferença )\n",
    "cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns,cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b9347-e205-49de-a102-8f650d99d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boruta n ta dando muito certo , mas eles selecionaria essas colunas\n",
    "# mas ao invexz de manual sozinho q é aas colunas que é importante para o modelo\n",
    "cols_selected_boruta = df6[['store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month', 'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'month_cos', 'day_sin', 'day_cos', 'week_of_year_cos']]\n",
    "list(cols_selected_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3123e5-3000-46be-a0f9-79b4de7c41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected_borutaa = df6[['store','promo','store_type','assortment','competition_distance','competition_open_since_month','competition_open_since_year','promo2','promo2_since_week','promo2_since_year','competition_time_month','promo_time_week','day_of_week_sin','day_of_week_cos','month_cos','month_sin','day_sin','day_cos','week_of_year_cos','week_of_year_sin']]\n",
    "cols_selected_borutaa\n",
    "\n",
    "#collumns to ad\n",
    "#adicionar essas duas colunas que eu tinha tirado \n",
    "cols_selected_boruta = cols_selected_borutaa.columns.tolist()\n",
    "\n",
    "# Adicionar as colunas 'date' e 'sales' à lista\n",
    "cols_selected_boruta.extend(['date', 'sales'])\n",
    "\n",
    "#final features\n",
    "cols_selected_boruta.extend(feat_to_add)\n",
    "cols_selected_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0245c9-f710-4032-a5d0-230ff30c6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_selected_boruta = df6[['is_promo', 'month_sin', 'school_holiday', 'state_holiday_christmas', 'state_holiday_easter_holiday', 'state_holiday_public_holiday', 'state_holiday_regular_day', 'week_of_year_sin', 'year']]\n",
    "list(cols_not_selected_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2526b-5add-4c0f-bcc8-3e48f425947e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3052f6-0e1c-4d4c-93cc-a3ce3e8c7216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad15badd-2cab-4cd1-8ad7-3d2c842da706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>promo</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>...</th>\n",
       "      <th>state_holiday_easter_holiday</th>\n",
       "      <th>state_holiday_public_holiday</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_of_year_sin</th>\n",
       "      <th>week_of_year_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8.568646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170968</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8.710290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.283871</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9.025816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.903226</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9.546527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.275806</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8.481151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.448387</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016776</th>\n",
       "      <td>682</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8.124447</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.351613</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016827</th>\n",
       "      <td>733</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>9.284148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.237097</td>\n",
       "      <td>10</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016863</th>\n",
       "      <td>769</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8.524367</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.240323</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017042</th>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8.410053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.145161</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017190</th>\n",
       "      <td>1097</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8.693161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.259677</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844338 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         store       date     sales  promo  school_holiday  store_type  \\\n",
       "0            1 2015-07-31  8.568646      1               1           2   \n",
       "1            2 2015-07-31  8.710290      1               1           0   \n",
       "2            3 2015-07-31  9.025816      1               1           0   \n",
       "3            4 2015-07-31  9.546527      1               1           2   \n",
       "4            5 2015-07-31  8.481151      1               1           0   \n",
       "...        ...        ...       ...    ...             ...         ...   \n",
       "1016776    682 2013-01-01  8.124447      0               1           1   \n",
       "1016827    733 2013-01-01  9.284148      0               1           1   \n",
       "1016863    769 2013-01-01  8.524367      0               1           1   \n",
       "1017042    948 2013-01-01  8.410053      0               1           1   \n",
       "1017190   1097 2013-01-01  8.693161      0               1           1   \n",
       "\n",
       "         assortment  competition_distance  competition_open_since_month  \\\n",
       "0                 1             -0.170968                             9   \n",
       "1                 1             -0.283871                            11   \n",
       "2                 1              1.903226                            12   \n",
       "3                 3             -0.275806                             9   \n",
       "4                 1              4.448387                             4   \n",
       "...             ...                   ...                           ...   \n",
       "1016776           1             -0.351613                             9   \n",
       "1016827           2             -0.237097                            10   \n",
       "1016863           2             -0.240323                             1   \n",
       "1017042           2             -0.145161                             1   \n",
       "1017190           2             -0.259677                             3   \n",
       "\n",
       "         competition_open_since_year  ...  state_holiday_easter_holiday  \\\n",
       "0                               2008  ...                             0   \n",
       "1                               2007  ...                             0   \n",
       "2                               2006  ...                             0   \n",
       "3                               2009  ...                             0   \n",
       "4                               2015  ...                             0   \n",
       "...                              ...  ...                           ...   \n",
       "1016776                         2006  ...                             0   \n",
       "1016827                         1999  ...                             0   \n",
       "1016863                         2013  ...                             0   \n",
       "1017042                         2013  ...                             0   \n",
       "1017190                         2002  ...                             0   \n",
       "\n",
       "         state_holiday_public_holiday  month_sin  month_cos   day_sin  \\\n",
       "0                                   0       -0.5  -0.866025  0.207912   \n",
       "1                                   0       -0.5  -0.866025  0.207912   \n",
       "2                                   0       -0.5  -0.866025  0.207912   \n",
       "3                                   0       -0.5  -0.866025  0.207912   \n",
       "4                                   0       -0.5  -0.866025  0.207912   \n",
       "...                               ...        ...        ...       ...   \n",
       "1016776                             1        0.5   0.866025  0.207912   \n",
       "1016827                             1        0.5   0.866025  0.207912   \n",
       "1016863                             1        0.5   0.866025  0.207912   \n",
       "1017042                             1        0.5   0.866025  0.207912   \n",
       "1017190                             1        0.5   0.866025  0.207912   \n",
       "\n",
       "          day_cos  week_of_year_sin  week_of_year_cos  day_of_week_sin  \\\n",
       "0        0.978148         -0.568065         -0.822984        -0.974928   \n",
       "1        0.978148         -0.568065         -0.822984        -0.974928   \n",
       "2        0.978148         -0.568065         -0.822984        -0.974928   \n",
       "3        0.978148         -0.568065         -0.822984        -0.974928   \n",
       "4        0.978148         -0.568065         -0.822984        -0.974928   \n",
       "...           ...               ...               ...              ...   \n",
       "1016776  0.978148          0.120537          0.992709         0.974928   \n",
       "1016827  0.978148          0.120537          0.992709         0.974928   \n",
       "1016863  0.978148          0.120537          0.992709         0.974928   \n",
       "1017042  0.978148          0.120537          0.992709         0.974928   \n",
       "1017190  0.978148          0.120537          0.992709         0.974928   \n",
       "\n",
       "         day_of_week_cos  \n",
       "0              -0.222521  \n",
       "1              -0.222521  \n",
       "2              -0.222521  \n",
       "3              -0.222521  \n",
       "4              -0.222521  \n",
       "...                  ...  \n",
       "1016776        -0.222521  \n",
       "1016827        -0.222521  \n",
       "1016863        -0.222521  \n",
       "1017042        -0.222521  \n",
       "1017190        -0.222521  \n",
       "\n",
       "[844338 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c86b39-77f9-43f7-b352-43fff9cac57e",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26281d15-5495-4f5d-8438-9259c34b5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificação e regressão e series temporais \n",
    "#deep leraning é classificação\n",
    "quando quer fazer previsão isso se chama predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4425edf2-6a54-4e7d-9343-c6a4a08ac359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# nao supervisionado - Clusterização\n",
    "# agrupamento/clusterização\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420b384-5e7e-430f-826d-a664467ba579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-supervisionado\n",
    "#ação     > <       ambiente\n",
    "\n",
    "#ação faz ação e recebe uma recompensa\n",
    "#e depois de um tempo quando ele só recebe recompensa positiva ele só faz aquela ação\n",
    "EX: igual capa de serie de netflix\n",
    "quando vc clica é a recompensa e ai acaba que vai aprendendo em qual vc mais clicka é a melhor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c4b8b-a68c-4482-b47b-cf3769c8af7d",
   "metadata": {},
   "source": [
    "# machine learning moddeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281624dd-d9e6-4ceb-a390-296f846dce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando as colunas mais relevantes para xtrain e xtest\n",
    "\n",
    "x_train = X_train[cols_selected_boruta_full]\n",
    "x_test = X_test[cols_selected_boruta_full]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7571d-b480-488e-9499-3aaf8a17cde5",
   "metadata": {},
   "source": [
    "## 1 Modelo de média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d979d71-1d90-4be7-bfbd-81fd90f0244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "para ter uma base doq é bom ou ruim , se eu fazer um ML e for pior que a média o algortmo nao está bom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "384814b1-affd-4ce1-8dc4-bd1672e7821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f83639b0-04f0-4236-8f75-c0e90ca0864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_error(model_name,y,y_hat):\n",
    "    mae = mean_absolute_error(y,y_hat)\n",
    "    mape = mean_absolute_percentage_error(y,y_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(y,y_hat))\n",
    "    return pd.DataFrame({'Model Name' : model_name,\n",
    "                         'MAE' : mae,\n",
    "                         'MAPE' : mape,\n",
    "                         'rmse' : rmse }, index=[0])\n",
    "    #index 0 n sei pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21382b5d-f3f8-4d5f-b992-1693e1de6fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1354.800353</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>1835.135542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name          MAE    MAPE         rmse\n",
       "0  Average Model  1354.800353  0.2064  1835.135542"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "#agora temos todas as predicoes medias por média por loja agora anexar no conjunto de dados original\n",
    "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename(columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "#predição \n",
    "yhat_baseline = aux1['predictions']\n",
    "#performace\n",
    "#usamos logaritmo para modularizar a variavel(colocar na variavel certa)\n",
    "#usamos log na variavel resposta sales(exponencial para voltar na variavel certa)(expm1)\n",
    "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1(yhat_baseline ) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f50fabe7-bc62-4652-ae48-ea295326bfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store', 'date', 'sales', 'promo', 'school_holiday', 'store_type',\n",
       "       'assortment', 'competition_distance', 'competition_open_since_month',\n",
       "       'competition_open_since_year', 'promo2', 'promo2_since_week',\n",
       "       'promo2_since_year', 'is_promo', 'year', 'competition_time_month',\n",
       "       'promo_time_week', 'state_holiday_christmas',\n",
       "       'state_holiday_easter_holiday', 'state_holiday_public_holiday',\n",
       "       'month_sin', 'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin',\n",
       "       'week_of_year_cos', 'day_of_week_sin', 'day_of_week_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdcbfe-3e12-430d-af50-9072be6b3c19",
   "metadata": {},
   "source": [
    "# 2 - regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301aca1c-3f50-4731-9664-cd28a440bf3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- date\nFeature names seen at fit time, yet now missing:\n- is_promo\n- school_holiday\n- state_holiday_christmas\n- state_holiday_easter_holiday\n- state_holiday_public_holiday\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m lr \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#prediction\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m y_hat_lr \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#performace \u001b[39;00m\n\u001b[1;32m     14\u001b[0m lr_result \u001b[38;5;241m=\u001b[39m ml_error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Regressior\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mexpm1(y_test) , np\u001b[38;5;241m.\u001b[39mexpm1(y_hat_lr))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/linear_model/_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/linear_model/_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- date\nFeature names seen at fit time, yet now missing:\n- is_promo\n- school_holiday\n- state_holiday_christmas\n- state_holiday_easter_holiday\n- state_holiday_public_holiday\n- ...\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=['date'])\n",
    "X_test = X_test.drop(columns=['date'])\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#model \n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#prediction\n",
    "y_hat_lr = lr.predict(x_test)\n",
    "\n",
    "#performace \n",
    "lr_result = ml_error('Linear Regressior', np.expm1(y_test) , np.expm1(y_hat_lr))\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2dccb-61e8-47b8-b87f-d9a00e83edc6",
   "metadata": {},
   "source": [
    "# 3 - regressão linear regularização - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eebe038f-affc-4aff-9867-c27a411116ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'Lasso Regressior',\n",
       " 'MAE': 1890.5097178841665,\n",
       " 'MAPE': 0.28978990131613386,\n",
       " 'RMSE': 2739.365070708826}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "\n",
    "\n",
    "#model \n",
    "lrr = Lasso(alpha = 0.01).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#prediction\n",
    "y_hat_lrr = lrr.predict(x_test)\n",
    "\n",
    "#performace \n",
    "lrr_result = ml_error('Lasso Regressior', np.expm1(y_test) , np.expm1(y_hat_lrr))\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28efc9-cf1a-4127-9257-ad3a3a028480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f81595-ae72-4713-8dd5-e5aa0d8aedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notase que os modelos lieares tiveram performace pior doq a média entao isso quer dizer que nosso modelo\n",
    "# nao é linear ele nao é simples ele é mais complexos , entao os proximos passo é testar modelos de regressao nao lineares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1eff2-c7e4-48e0-ad77-f2e7859acb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d84ed2-5726-4f9e-91df-a3605012c3b6",
   "metadata": {},
   "source": [
    "# 4 - random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cd7241c-f609-4d27-b0ac-90b4a9aca1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>688.51303</td>\n",
       "      <td>0.101249</td>\n",
       "      <td>1025.568281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name        MAE      MAPE         rmse\n",
       "0  Random Forest Regressor  688.51303  0.101249  1025.568281"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# model \n",
    "#esti = quantas arvores aleatoria vai criar, criar em paralelo , random = origem dos numero aleatorio principamente na hora de escolher as features\n",
    "#crio uma mesma origem aleatoria\n",
    "rf = RandomForestRegressor(n_estimators=37,n_jobs=-1,random_state=42).fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predict\n",
    "yhat_rf = rf.predict(x_test)\n",
    "\n",
    "#performace\n",
    "rf_result = ml_error('Random Forest Regressor',np.expm1(y_test),np.expm1(yhat_rf))\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc20f2-d28d-42a9-8dce-7fe67ed2fcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfd31a-254b-4654-afe0-057bcf748b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ce2d34-4060-4575-a8fc-296cc4836735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6307909-5f5c-4651-bf6b-726ef0aca608",
   "metadata": {},
   "source": [
    "# 5 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0557c237-5992-49e1-8834-988691f68c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [13:31:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytee\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>1695.767243</td>\n",
       "      <td>0.251781</td>\n",
       "      <td>2478.381381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name          MAE      MAPE         rmse\n",
       "0  XGBoost Regressor  1695.767243  0.251781  2478.381381"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# model \n",
    "#obj usar no problema de regressao\n",
    "#eta quantas passagens usa pra fzer o aprendizado\n",
    "#max maxima profundida da arvore\n",
    "# sub quantas amostra ou % das variaveis que quero pega\n",
    "# col varias arvores e quero pega varias arvores\n",
    "#\n",
    "#\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                             n_estimators=100,\n",
    "                             eta=0.01,\n",
    "                             max_depth=10,\n",
    "                             subsample=0.7,\n",
    "                             colsample_bytee=0.9,\n",
    "                                ).fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predict\n",
    "yhat_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "#performace\n",
    "xgb_result = ml_error('XGBoost Regressor',np.expm1(y_test),np.expm1(yhat_xgb))\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3423d69-aac8-4681-9338-3f9278b88a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cfa3a37-74ad-40dd-82df-ceb0c53be4df",
   "metadata": {},
   "source": [
    "# comparar models performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63054b79-8674-4f56-acaa-c04c651e2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_result = pd.concat([baseline_result,lr_result,lrr_result,rf_result,xgb_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca24ab59-0fa0-4594-bd40-3aa31b67e7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>693.652884</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>1031.716970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1354.800353</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>1835.135542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>1695.767243</td>\n",
       "      <td>0.251781</td>\n",
       "      <td>2478.381381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regressior</td>\n",
       "      <td>1867.089774</td>\n",
       "      <td>0.292694</td>\n",
       "      <td>2671.049215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regressior</td>\n",
       "      <td>1891.704881</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>2744.451737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name          MAE      MAPE         rmse\n",
       "0  Random Forest Regressor   693.652884  0.101926  1031.716970\n",
       "0            Average Model  1354.800353  0.206400  1835.135542\n",
       "0        XGBoost Regressor  1695.767243  0.251781  2478.381381\n",
       "0        Linear Regressior  1867.089774  0.292694  2671.049215\n",
       "0         Lasso Regressior  1891.704881  0.289106  2744.451737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_result.sort_values('rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00549aa-d2c8-4ad5-89d9-c27706d1ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os modelos nao lineares estao com performace melhro que media\n",
    "# esse erro nao pode usar pq o modelo foi treinado em vendas nas ultimas semanas\n",
    "#tem que fazer a separação do treino e teste\n",
    "#vamo aprender cross validatition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000efeef-340f-4393-ac19-ef70e9b02553",
   "metadata": {},
   "source": [
    "# Croos Validatition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc806331-392e-4e73-9b43-a84c91e4d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresssao e clasificação \n",
    "\n",
    "pegar varias fatias do dataset para usar como treino e teste\n",
    "cada vez que faz o cross validatition pega uma parte diferente do data set\n",
    "\n",
    "cada vez que faz o cross validatition tem um erro(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664e9ea-f202-4739-8a80-cbe08fda9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series\n",
    "\n",
    "a diferença é que nao pode fazer a separação aleatoria mas sim\n",
    "respeitar o periodo  de tempo \n",
    "\n",
    "pegar do inicio até certo tempo depois \n",
    "pega inicio+certo tempo até outro tempo\n",
    "pega inici+certotempo+outrotempo ate o final e etc\n",
    "\n",
    "\n",
    "nosso algortimo é time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3555b25-f281-4923-a5fb-a3d5311e7ed7",
   "metadata": {},
   "source": [
    "# implementando cross validatitiomn time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3c6f971-7b6a-49ff-b79b-b5dfccb453b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>promo</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>...</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_of_year_cos</th>\n",
       "      <th>week_of_year_sin</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47945</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170968</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.443762</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.443762</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.443762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47946</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.283871</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.547722</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.547722</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.547722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47947</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.903226</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.927712</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.927712</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.927712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47948</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.275806</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>9.091669</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>9.091669</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>9.091669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47949</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.448387</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.502080</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.502080</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8.502080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store  promo  store_type  assortment  competition_distance  \\\n",
       "47945      1      1           2           1             -0.170968   \n",
       "47946      2      1           0           1             -0.283871   \n",
       "47947      3      1           0           1              1.903226   \n",
       "47948      4      1           2           3             -0.275806   \n",
       "47949      5      1           0           1              4.448387   \n",
       "\n",
       "       competition_open_since_month  competition_open_since_year  promo2  \\\n",
       "47945                             9                         2008       0   \n",
       "47946                            11                         2007       1   \n",
       "47947                            12                         2006       1   \n",
       "47948                             9                         2009       0   \n",
       "47949                             4                         2015       0   \n",
       "\n",
       "       promo2_since_week  promo2_since_year  ...   day_sin   day_cos  \\\n",
       "47945                 25               2015  ... -0.587785 -0.809017   \n",
       "47946                 13               2010  ... -0.587785 -0.809017   \n",
       "47947                 14               2011  ... -0.587785 -0.809017   \n",
       "47948                 25               2015  ... -0.587785 -0.809017   \n",
       "47949                 25               2015  ... -0.587785 -0.809017   \n",
       "\n",
       "       week_of_year_cos  week_of_year_sin       date     sales       date  \\\n",
       "47945         -0.992709          0.120537 2015-06-18  8.443762 2015-06-18   \n",
       "47946         -0.992709          0.120537 2015-06-18  8.547722 2015-06-18   \n",
       "47947         -0.992709          0.120537 2015-06-18  8.927712 2015-06-18   \n",
       "47948         -0.992709          0.120537 2015-06-18  9.091669 2015-06-18   \n",
       "47949         -0.992709          0.120537 2015-06-18  8.502080 2015-06-18   \n",
       "\n",
       "          sales       date     sales  \n",
       "47945  8.443762 2015-06-18  8.443762  \n",
       "47946  8.547722 2015-06-18  8.547722  \n",
       "47947  8.927712 2015-06-18  8.927712  \n",
       "47948  9.091669 2015-06-18  9.091669  \n",
       "47949  8.502080 2015-06-18  8.502080  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar se as colunas 'date' e 'sales' estão presentes em x_train\n",
    "if 'date' not in x_train.columns or 'sales' not in x_train.columns:\n",
    "    # Se não estiverem presentes, adicione-as ao DataFrame x_train\n",
    "    x_train['date'] = df6['date']\n",
    "    x_train['sales'] = df6['sales']\n",
    "\n",
    "# Selecionar as colunas desejadas do DataFrame original\n",
    "x_training = x_train[cols_selected_boruta_full]\n",
    "\n",
    "# Verificar as primeiras linhas do novo DataFrame\n",
    "x_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ac13b55-1a04-48da-b96c-701beaff4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer primeira parte que é pegar os dados do começo\n",
    "#.timedelta fez eu pegar as primeiras 7 semanas\n",
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "            # start and end date for validation\n",
    "            validation_start_date = x_training['date'].max() - datetime.timedelta(days=k*6*7)\n",
    "            validation_end_date = x_training['date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "            # filtering dataset\n",
    "            training = x_training[x_training['date'] < validation_start_date]\n",
    "            validation = x_training[(x_training['date'] >= validation_start_date) &(x_training['date'] <= validation_end_date)]\n",
    "            # training and validation dataset\n",
    "            # training\n",
    "            xtraining = training.drop( ['date', 'sales'], axis=1 )\n",
    "            ytraining = training['sales']\n",
    "            # validation\n",
    "            xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "            yvalidation = validation['sales']\n",
    "            # model\n",
    "            m = model.fit( xtraining, ytraining )\n",
    "            # prediction\n",
    "            yhat = m.predict( xvalidation )\n",
    "            # performance\n",
    "            m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1(yhat ) )\n",
    "            # store performance of each kfold iteration\n",
    "            mae_list.append( m_result['MAE'] )\n",
    "            mape_list.append( m_result['MAPE'] )\n",
    "            rmse_list.append( m_result['RMSE'] )\n",
    "            return pd.DataFrame( {'Model Name': model_name,\n",
    "            'MAE CV': np.round( np.mean( mae_list ), 2 ).astype(str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "            'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "            'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str )}, index=[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30247996-4b2d-420f-8d49-d849fe28e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=kfold)\n",
    "    for train_index, test_index in tscv.split(x_training):\n",
    "        if verbose:\n",
    "            print('\\nKFold Number: {}'.format(kfold))\n",
    "            # Training and validation dataset\n",
    "            # Training\n",
    "            xtraining = x_training.iloc[train_index].drop(['date', 'sales'], axis=1)\n",
    "            ytraining = x_training.iloc[train_index]['sales']\n",
    "            # Validation\n",
    "            xvalidation = x_training.iloc[test_index].drop(['date', 'sales'], axis=1)\n",
    "            yvalidation = x_training.iloc[test_index]['sales']\n",
    "            # Model\n",
    "            m = model.fit(xtraining, ytraining)\n",
    "            # Prediction\n",
    "            yhat = m.predict(xvalidation)\n",
    "            # Performance\n",
    "            m_result = ml_error(model_name, np.expm1(yvalidation), np.expm1(yhat))\n",
    "            # Store performance of each kfold iteration\n",
    "            mae_list.append(m_result['MAE'])\n",
    "            mape_list.append(m_result['MAPE'])\n",
    "            rmse_list.append(m_result['RMSE'])\n",
    "\n",
    "    return pd.DataFrame({'Model Name': model_name,\n",
    "                         'MAE CV': np.round(np.mean(mae_list), 2).astype(str) + ' +/- ' + np.round(np.std(mae_list), 2).astype(str),\n",
    "                         'MAPE CV': np.round(np.mean(mape_list), 2).astype(str) + ' +/- ' + np.round(np.std(mape_list), 2).astype(str),\n",
    "                         'RMSE CV': np.round(np.mean(rmse_list), 2).astype(str) + ' +/- ' + np.round(np.std(rmse_list), 2).astype(str)}, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73e6cb21-7d7d-4825-aa5c-96c115a20384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store', 'promo', 'store_type', 'assortment', 'competition_distance',\n",
       "       'competition_open_since_month', 'competition_open_since_year', 'promo2',\n",
       "       'promo2_since_week', 'promo2_since_year', 'competition_time_month',\n",
       "       'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'month_sin',\n",
       "       'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin',\n",
       "       'week_of_year_cos', 'date', 'sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca904e9-11ca-495c-80f2-9a25fb7cbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas desejadas do DataFrame original\n",
    "x_training = ['store', 'promo', 'store_type', 'assortment', 'competition_distance',\n",
    "       'competition_open_since_month', 'competition_open_since_year', 'promo2',\n",
    "       'promo2_since_week', 'promo2_since_year', 'competition_time_month',\n",
    "       'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'month_sin',\n",
    "       'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin',\n",
    "       'week_of_year_cos', 'date', 'sales']\n",
    "fazer separação de traing \n",
    "e validaçãlo para fazer as separações\n",
    "xtraining n pode ter data e sales\n",
    "y train é o sales\n",
    "xvalidation tbm nao pode ter data sales\n",
    "yvalidation  é sales\n",
    "ytraining é só o sales\n",
    "\n",
    "fazer a divisao tbm do xval e yval \n",
    " mostrar mae mape e rmse \n",
    "chamar uma funcao chamada ml_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2898c-dbe0-4416-a8ab-58cbc2e209c9",
   "metadata": {},
   "source": [
    "# Cross validatition nos modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "077fa0de-e69a-45d7-a1ca-a8f99ad5803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "\n",
    "\n",
    "\n",
    "lr_result_cv = cross_validation(x_training, 5 , 'Linear Regressor', lr,verbose=False)\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d753b-fcf4-49d0-97c0-272c1cc243e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "\n",
    "\n",
    "\n",
    "lrr_result_cv = cross_validation(x_training, 5 , 'Lasso Regressor', lrr,verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2315e34-836f-4dfa-9c29-fed1e05d5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "\n",
    "lrr_result_cv = cross_validation(x_training, 5 , 'Lasso Regressor', lrr,verbose=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcee08b-c059-4e10-9570-1fbaf6f1dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "\n",
    "\n",
    "rf_result_cv = cross_validation(x_training, 5 , 'Random Forest Regressor', rf,verbose=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacf32a-468c-407a-8159-e9c49835a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "\n",
    "\n",
    "xgb_result_cv = cross_validation(x_training, 5 , 'XGB', model_xgb,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c25311-9efe-4794-afa2-9aa23981b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real Result - Cross Validatition\n",
    "\n",
    "\n",
    "modelling_result = pd.concat([baseline_result,lr_result_cv,lrr_result_cv,rf_result_cv,xgb_result_cv])\n",
    "modelling_result.sort_values('rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdcdd91-2e14-4649-aff5-b1f4908c6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar o random FOrest\n",
    "\n",
    "#mas vamos continuar com XGB para treinar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813af710-6c5e-4395-8390-b456c8d13a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb945e12-228e-44e2-8b5c-5092828c09fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869f412-4cb0-427a-8884-9d4252262dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
