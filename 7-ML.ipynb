{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0730fc-0138-4908-96a6-08663dd991bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "import pandas as pd\n",
    "import inflection\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime\n",
    "df_sales_raw = pd.read_csv('train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('store.csv', low_memory=False)\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')\n",
    "df1 = df_raw.copy()\n",
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "            'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "            'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "            'Promo2SinceYear', 'PromoInterval']\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "df1.columns = cols_new\n",
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "df1['competition_open_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n",
    "df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "month_map = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "df1['promo_interval'] = df1['promo_interval'].fillna(0)\n",
    "df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)\n",
    "df2 = df1.copy()\n",
    "df2['year'] = df2['date'].dt.year\n",
    "df2['month'] = df2['date'].dt.month\n",
    "df2['day'] = df2['date'].dt.day\n",
    "df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "df2['competition_since'] = df2.apply(lambda x: datetime.datetime(year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1), axis=1)\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since']) / 30).apply(lambda x: x.days).astype(int)\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime(year=x['competition_open_since_year'],month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30).apply( lambda x: x.days ).astype( int )\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply(lambda x: x.days ).astype( int )\n",
    "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "df3 = df2.copy()\n",
    "df3\n",
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]\n",
    "cols_drop = ['customers','open','promo_interval','month_map']\n",
    "df3 = df3.drop(cols_drop,axis=1)\n",
    "df3.columns\n",
    "num_attributes = df3.select_dtypes(include=['int64', 'float64'])\n",
    "cat_attributes = df3.select_dtypes(exclude=['int64','float64','datetime64[ns]'])\n",
    "df4 = df3.copy()\n",
    "aux1 = df4.select_dtypes(include = ['int64','float64'])\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
    "rs = RobustScaler()\n",
    "df4['competition_distance'] = rs.fit_transform(df4[['competition_distance']].values)\n",
    "rs1 = RobustScaler()\n",
    "df4['competition_time_month'] = rs1.fit_transform(df4[['competition_time_month']].values)\n",
    "mms = MinMaxScaler()\n",
    "df4['promo_time_week'] = mms.fit_transform(df4[['promo_time_week']].values)\n",
    "mms1 = MinMaxScaler()\n",
    "df4['year'] = mms1.fit_transform(df4[['year']].values)\n",
    "df4 = pd.get_dummies(df4, prefix=['state_holiday'], columns=['state_holiday'], dtype=int)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df4['store_type'] = le.fit_transform(df4['store_type'])\n",
    "assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
    "df4['assortment'] = df4['assortment'].map(assortment_dict)\n",
    "df4['month_sin'] = df4['month'].apply(lambda x: np.sin(x * (2. * np.pi/12)))\n",
    "df4['sales'] = np.log1p(df4['sales'])\n",
    "df4['month_cos'] = df4['month'].apply(lambda x: np.cos(x *(2. * np.pi/12)))\n",
    "df4['day_sin'] = df4['day'].apply(lambda x: np.sin(x * (2. * np.pi/30)))\n",
    "df4['day_cos'] = df4['day'].apply(lambda x: np.cos(x *(2. * np.pi/30)))\n",
    "df4['week_of_year_sin'] = df4['week_of_year'].apply(lambda x: np.sin(x * (2. * np.pi/52)))\n",
    "df4['week_of_year_cos'] = df4['week_of_year'].apply(lambda x: np.cos(x *(2. * np.pi/52)))\n",
    "df4['day_of_week_sin'] = df4['day_of_week'].apply(lambda x: np.sin(x * (2. * np.pi/7)))\n",
    "df4['day_of_week_cos'] = df4['day_of_week'].apply(lambda x: np.cos(x *(2. * np.pi/7)))\n",
    "df6 = df4.copy()\n",
    "cols_drop = ['week_of_year','day','month','day_of_week','promo_since','competition_since','year_week']\n",
    "df6 = df6.drop(cols_drop,axis=1)\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train_n = X_train.drop(['date', 'sales'], axis=1).values\n",
    "y_train_n = y_train.values.ravel()\n",
    "# Criar um classificador RandomForest simples com menos estimadores\n",
    "#rf = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42)\n",
    "# Passar o RandomForestClassifier para o BorutaPy\n",
    "#boruta = BorutaPy(rf, n_estimators=10, random_state=20)\n",
    "\n",
    "#boruta.fit(X_train_n, y_train_n)\n",
    "cols_selected_borutaa = df6[['store','promo','store_type','assortment','competition_distance','competition_open_since_month','competition_open_since_year','promo2','promo2_since_week','promo2_since_year','competition_time_month','promo_time_week','day_of_week_sin','day_of_week_cos','month_cos','month_sin','day_sin','day_cos','week_of_year_cos','week_of_year_sin']]\n",
    "cols_selected_borutaa\n",
    "cols_selected_boruta = cols_selected_borutaa.columns.tolist()\n",
    "#cols_selected_boruta.extend(['date', 'sales'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c86b39-77f9-43f7-b352-43fff9cac57e",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26281d15-5495-4f5d-8438-9259c34b5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificação e regressão e series temporais \n",
    "#deep leraning é classificação\n",
    "quando quer fazer previsão isso se chama predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4425edf2-6a54-4e7d-9343-c6a4a08ac359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# nao supervisionado - Clusterização\n",
    "# agrupamento/clusterização\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420b384-5e7e-430f-826d-a664467ba579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-supervisionado\n",
    "#ação     > <       ambiente\n",
    "\n",
    "#ação faz ação e recebe uma recompensa\n",
    "#e depois de um tempo quando ele só recebe recompensa positiva ele só faz aquela ação\n",
    "EX: igual capa de serie de netflix\n",
    "quando vc clica é a recompensa e ai acaba que vai aprendendo em qual vc mais clicka é a melhor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c4b8b-a68c-4482-b47b-cf3769c8af7d",
   "metadata": {},
   "source": [
    "# machine learning moddeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281624dd-d9e6-4ceb-a390-296f846dce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando as colunas mais relevantes para xtrain e xtest\n",
    "\n",
    "x_train = X_train[ cols_selected_boruta ]\n",
    "x_test = X_test[ cols_selected_boruta ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7571d-b480-488e-9499-3aaf8a17cde5",
   "metadata": {},
   "source": [
    "## 1 Modelo de média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d979d71-1d90-4be7-bfbd-81fd90f0244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "para ter uma base doq é bom ou ruim , se eu fazer um ML e for pior que a média o algortmo nao está bom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384814b1-affd-4ce1-8dc4-bd1672e7821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83639b0-04f0-4236-8f75-c0e90ca0864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_error(model_name,y,y_hat):\n",
    "    mae = mean_absolute_error(y,y_hat)\n",
    "    mape = mean_absolute_percentage_error(y,y_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(y,y_hat))\n",
    "    return pd.DataFrame({'Model Name' : model_name,\n",
    "                         'MAE' : mae,\n",
    "                         'MAPE' : mape,\n",
    "                         'rmse' : rmse }, index=[0])\n",
    "    #index 0 n sei pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21382b5d-f3f8-4d5f-b992-1693e1de6fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1354.800353</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>1835.135542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name          MAE    MAPE         rmse\n",
       "0  Average Model  1354.800353  0.2064  1835.135542"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "#agora temos todas as predicoes medias por média por loja agora anexar no conjunto de dados original\n",
    "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename(columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "#predição \n",
    "yhat_baseline = aux1['predictions']\n",
    "#performace\n",
    "#usamos logaritmo para modularizar a variavel(colocar na variavel certa)\n",
    "#usamos log na variavel resposta sales(exponencial para voltar na variavel certa)(expm1)\n",
    "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1(yhat_baseline ) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fabe7-bc62-4652-ae48-ea295326bfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3cdcbfe-3e12-430d-af50-9072be6b3c19",
   "metadata": {},
   "source": [
    "# 2 - regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301aca1c-3f50-4731-9664-cd28a440bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regressior</td>\n",
       "      <td>1867.089774</td>\n",
       "      <td>0.292694</td>\n",
       "      <td>2671.049215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name          MAE      MAPE         rmse\n",
       "0  Linear Regressior  1867.089774  0.292694  2671.049215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#model \n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#prediction\n",
    "y_hat_lr = lr.predict(x_test)\n",
    "\n",
    "#performace \n",
    "lr_result = ml_error('Linear Regressior', np.expm1(y_test) , np.expm1(y_hat_lr))\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2dccb-61e8-47b8-b87f-d9a00e83edc6",
   "metadata": {},
   "source": [
    "# 3 - regressão linear regularização - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebe038f-affc-4aff-9867-c27a411116ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regressior</td>\n",
       "      <td>1891.704881</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>2744.451737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Name          MAE      MAPE         rmse\n",
       "0  Lasso Regressior  1891.704881  0.289106  2744.451737"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "\n",
    "\n",
    "#model \n",
    "lrr = Lasso(alpha = 0.01).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#prediction\n",
    "y_hat_lrr = lrr.predict(x_test)\n",
    "\n",
    "#performace \n",
    "lrr_result = ml_error('Lasso Regressior', np.expm1(y_test) , np.expm1(y_hat_lrr))\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28efc9-cf1a-4127-9257-ad3a3a028480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f81595-ae72-4713-8dd5-e5aa0d8aedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notase que os modelos lieares tiveram performace pior doq a média entao isso quer dizer que nosso modelo\n",
    "# nao é linear ele nao é simples ele é mais complexos , entao os proximos passo é testar modelos de regressao nao lineares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1eff2-c7e4-48e0-ad77-f2e7859acb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d84ed2-5726-4f9e-91df-a3605012c3b6",
   "metadata": {},
   "source": [
    "# 4 - random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7241c-f609-4d27-b0ac-90b4a9aca1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# model \n",
    "#esti = quantas arvores aleatoria vai criar, criar em paralelo , random = origem dos numero aleatorio principamente na hora de escolher as features\n",
    "#crio uma mesma origem aleatoria\n",
    "rf = RandomForestRegressor(n_estimators=37,n_jobs=-1,random_state=42).fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predict\n",
    "yhat_rf = rf.predict(x_test)\n",
    "\n",
    "#performace\n",
    "rf_result = ml_error('Random Forest Regressor',np.expm1(y_test),np.expm1(yhat_rf))\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc20f2-d28d-42a9-8dce-7fe67ed2fcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfd31a-254b-4654-afe0-057bcf748b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ce2d34-4060-4575-a8fc-296cc4836735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6307909-5f5c-4651-bf6b-726ef0aca608",
   "metadata": {},
   "source": [
    "# 5 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0557c237-5992-49e1-8834-988691f68c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f/.pyenv/versions/3.12.2/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [13:31:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytee\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>1695.767243</td>\n",
       "      <td>0.251781</td>\n",
       "      <td>2478.381381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name          MAE      MAPE         rmse\n",
       "0  XGBoost Regressor  1695.767243  0.251781  2478.381381"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# model \n",
    "#obj usar no problema de regressao\n",
    "#eta quantas passagens usa pra fzer o aprendizado\n",
    "#max maxima profundida da arvore\n",
    "# sub quantas amostra ou % das variaveis que quero pega\n",
    "# col varias arvores e quero pega varias arvores\n",
    "#\n",
    "#\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                             n_estimators=100,\n",
    "                             eta=0.01,\n",
    "                             max_depth=10,\n",
    "                             subsample=0.7,\n",
    "                             colsample_bytee=0.9,\n",
    "                                ).fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predict\n",
    "yhat_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "#performace\n",
    "xgb_result = ml_error('XGBoost Regressor',np.expm1(y_test),np.expm1(yhat_xgb))\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3423d69-aac8-4681-9338-3f9278b88a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cfa3a37-74ad-40dd-82df-ceb0c53be4df",
   "metadata": {},
   "source": [
    "# comparar models performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63054b79-8674-4f56-acaa-c04c651e2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_result = pd.concat([baseline_result,lr_result,lrr_result,rf_result,xgb_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca24ab59-0fa0-4594-bd40-3aa31b67e7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>693.652884</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>1031.716970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1354.800353</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>1835.135542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>1695.767243</td>\n",
       "      <td>0.251781</td>\n",
       "      <td>2478.381381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regressior</td>\n",
       "      <td>1867.089774</td>\n",
       "      <td>0.292694</td>\n",
       "      <td>2671.049215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regressior</td>\n",
       "      <td>1891.704881</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>2744.451737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name          MAE      MAPE         rmse\n",
       "0  Random Forest Regressor   693.652884  0.101926  1031.716970\n",
       "0            Average Model  1354.800353  0.206400  1835.135542\n",
       "0        XGBoost Regressor  1695.767243  0.251781  2478.381381\n",
       "0        Linear Regressior  1867.089774  0.292694  2671.049215\n",
       "0         Lasso Regressior  1891.704881  0.289106  2744.451737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_result.sort_values('rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00549aa-d2c8-4ad5-89d9-c27706d1ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os modelos nao lineares estao com performace melhro que media\n",
    "# esse erro nao pode usar pq o modelo foi treinado em vendas nas ultimas semanas\n",
    "#tem que fazer a separação do treino e teste\n",
    "#vamo aprender cross validatition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a8710-447b-4d1c-affb-8e2d16677b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc806331-392e-4e73-9b43-a84c91e4d2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664e9ea-f202-4739-8a80-cbe08fda9f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce887a-cc72-4f05-a018-7e8c685a970b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6f971-7b6a-49ff-b79b-b5dfccb453b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac13b55-1a04-48da-b96c-701beaff4428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fb4af-4e95-4fa9-8105-696bcefe6e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6cb21-7d7d-4825-aa5c-96c115a20384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4321c-6382-48c2-a25e-878284f34390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca904e9-11ca-495c-80f2-9a25fb7cbc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
